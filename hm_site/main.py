import os
import re
import time
from datetime import datetime
from random import randint

from requests import Session

from bs4 import BeautifulSoup

from pandas import DataFrame
from pandas import ExcelWriter
from pandas import read_excel

from data.data import category_data_list
# from data.data import id_region_dict
# from functions import colors_format
# from functions import sizes_format
# from functions import translator
from functions import get_exchange_rate

start_time = datetime.now()

rub = get_exchange_rate()

print(f'–ö—É—Ä—Å EUR/RUB: {rub}')

url = "https://www2.hm.com/de_de/index.html"

headers = {
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '
                  'Chrome/124.0.0.0 Safari/537.36',
}


# –ü–æ–ª—É—á–∞–µ–º html —Ä–∞–∑–º–µ—Ç–∫—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
def get_html(url: str, headers: dict, session: Session) -> str:
    try:
        response = session.get(url=url, headers=headers, timeout=60)

        if response.status_code != 200:
            print(f'status_code: {response.status_code}')

        html = response.text
        return html
    except Exception as ex:
        print(ex)


# –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü
def get_pages(html: str) -> int:
    soup = BeautifulSoup(html, 'lxml')

    try:
        pages = int(soup.find('nav', {'aria-label': 'Paginierung'}).find_all('li')[-2].text.strip())
    except Exception as ex:
        print(ex)
        pages = 1

    return pages


# –ü–æ–ª—É—á–∞–µ–º —Å—Å—ã–ª–∫–∏ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Ç–æ–≤–∞—Ä–æ–≤
def get_category_urls(url: str, headers: dict) -> None:
    category_data_list = []

    with Session() as session:
        html = get_html(url=url, headers=headers, session=session)

        soup = BeautifulSoup(html, 'lxml')

        try:
            data = soup.find('ul', class_='MLEL').find_all('li')

            for item in data:
                category_name = item.text
                category_url = f"https://www2.hm.com{item.find('a').get('href')}"

                category_data_list.append(
                    (category_name, category_url)
                )

        except Exception as ex:
            print(ex)

        if not os.path.exists('data'):
            os.makedirs('data')

        with open(f'data/category_data_list.txt', 'w', encoding='utf-8') as file:
            print(*category_data_list, file=file, sep='\n')


# –ü–æ–ª—É—á–∞–µ–º —Å—Å—ã–ª–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤
def get_product_urls(category_data_list: list, headers: dict) -> list[dict]:
    products_data_list = []
    id_products_set = set()

    with Session() as session:
        for category_dict in category_data_list:
            for category_name, category_list in category_dict.items():
                for product_tuple in category_list[:1]:
                    product_urls = []
                    subcategory_name, category_url = product_tuple

                    time.sleep(1)

                    try:
                        html = get_html(url=category_url, headers=headers, session=session)
                    except Exception as ex:
                        print(f"{category_url} - {ex}")
                        continue

                    pages = get_pages(html=html)
                    print(f'–í –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category_name}: {pages} —Å—Ç—Ä–∞–Ω–∏—Ü')

                    # for page in range(1, pages + 1):
                    for page in range(1, 2):
                        page_product_url = f"{category_url}?page={page}"
                        try:
                            html = get_html(url=page_product_url, headers=headers, session=session)
                        except Exception as ex:
                            print(f"{page_product_url} - {ex}")
                            continue

                        if not html:
                            continue

                        soup = BeautifulSoup(html, 'lxml')

                        try:
                            product_items = soup.find('div',
                                                      id='products-listing-section').find_next().find_next_sibling()
                            for product_item in product_items:
                                try:
                                    product_url = product_item.find('a').get('href')
                                except Exception as ex:
                                    print(ex)
                                    continue
                                product_urls.append(product_url)
                                id_products_set.add(product_url)
                        except Exception as ex:
                            print(ex)

                        products_data_list.append(
                            {
                                (category_name, subcategory_name): product_urls
                            }
                        )

                        print(f'–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {page}/{pages} —Å—Ç—Ä–∞–Ω–∏—Ü')

                    print(f'–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: –∫–∞—Ç–µ–≥–æ—Ä–∏—è {category_name}/{subcategory_name} - {len(product_urls)} —Ç–æ–≤–∞—Ä–æ–≤!')

    if not os.path.exists('data'):
        os.makedirs(f'data')

    with open(f'data/products_data_list.py', 'w', encoding='utf-8') as file:
        print(products_data_list, file=file, sep='\n')

    return products_data_list


# –§—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
def get_products_data(products_data_list: dict, type_product: str) -> None:
    result_data = []
    processed_urls = []

    with Session() as session:
        for dict_item in products_data_list:
            product_urls = []
            key, values = list(dict_item.keys())[0], list(dict_item.values())[0]

            for product_url in values:
                if product_url not in processed_urls:
                    processed_urls.append(product_url)
                    product_urls.append(product_url)
            category_name = key[0]
            subcategory_name = key[1]

            print(f'–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {category_name}/{subcategory_name}')

            for i, product_url in enumerate(product_urls, 1):
                try:
                    time.sleep(1)
                    html = get_html(url=product_url, headers=headers, session=session)
                except Exception as ex:
                    print(f"{product_url} - {ex}")
                    continue

                if not html:
                    continue

                soup = BeautifulSoup(html, 'lxml')

                try:
                    id_product = product_url.split('.')[-2]
                except Exception:
                    id_product = None

                try:
                    reference = ''
                except Exception:
                    reference = None

                try:
                    name_product = f"H&M {}"
                except Exception:
                    name_product = None

                try:
                    price = 0
                    price = round(price * rub)
                except Exception:
                    price = 0

                try:
                    color_original = ''
                    color_ru = colors_format_ru(value=color_original)
                except Exception:
                    color_original = None
                    color_ru = None

                try:
                    id_color = ''
                except Exception:
                    id_color = ''

                try:
                    image_urls_list = []
                    main_image = ''
                    additional_images = []
                except Exception:
                    main_image = None
                    additional_images = None

                try:
                    if category_name == '–ñ–µ–Ω—â–∏–Ω—ã':
                        gender = '–∂–µ–Ω—Å–∫–∏–π'
                    elif category_name == '–ú—É–∂—á–∏–Ω—ã':
                        gender = '–º—É–∂—Å–∫–æ–π'
                    else:
                        gender = category_name
                except Exception:
                    gender = None

                try:
                    raw_description = ''
                    description = f"üöö –î–û–°–¢–ê–í–ö–ê –ò–ó –ï–í–†–û–ü–´ üåç‚úàÔ∏è<br/>‚úÖ –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–π.<br/>‚úÖ –ü–æ–ª–Ω—ã–π –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç –±—Ä–µ–Ω–¥a Zara. –ë–æ–ª–µ–µ 10 000 —Ç–æ–≤–∞—Ä–æ–≤ –∂–¥—É—Ç –≤–∞—Å –≤ –ø—Ä–æ—Ñ–∏–ª–µ –Ω–∞—à–µ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞! üè∑Ô∏è<br/>‚úÖ –ë–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –Ω—É–∂–Ω—ã—Ö –≤–µ—â–µ–π –≤–Ω—É—Ç—Ä–∏ –Ω–∞—à–µ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞. –ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å, —á—Ç–æ–±—ã –≤—Å–µ–≥–¥–∞ –±—ã—Ç—å –≤ –∫—É—Ä—Å–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–π –∏ –∞–∫—Ü–∏–π! üîçüì≤<br/>{raw_description}<br/>üì£ –ü—Ä–∏ –≤—ã–±–æ—Ä–µ —Ç–æ–≤–∞—Ä–∞ –æ—Ä–∏–µ–Ω—Ç–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ –ï–í–†–û–ü–ï–ô–°–ö–ò–ô —Ä–∞–∑–º–µ—Ä!"
                except Exception:
                    description = None

                brand = 'Zara'

                care = "–ú–∞—à–∏–Ω–Ω–∞—è —Å—Ç–∏—Ä–∫–∞ –ø—Ä–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–µ –¥–æ 30¬∫C —Å –∫–æ—Ä–æ—Ç–∫–∏–º —Ü–∏–∫–ª–æ–º –æ—Ç–∂–∏–º–∞. –û—Ç–±–µ–ª–∏–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–µ—â–µ–Ω–æ. " \
                       "–ì–ª–∞–¥–∏—Ç—å –ø—Ä–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–µ –¥–æ 110¬∫C. –ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–∞—à–∏–Ω–Ω—É—é —Å—É—à–∫—É. –°—Ç–∏—Ä–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ."

                if category_name == '–ñ–µ–Ω—â–∏–Ω—ã':
                    model_height = '175'
                elif category_name == '–ú—É–∂—á–∏–Ω—ã':
                    model_height = '180'
                else:
                    model_height = None

                if category_name == '–ñ–µ–Ω—â–∏–Ω—ã':
                    model_size = '44'
                elif category_name == '–ú—É–∂—á–∏–Ω—ã':
                    model_size = '48'
                else:
                    model_size = None

                try:
                    composition = ''
                    material = ''
                except Exception:
                    material = None
                    composition = None

                try:
                    sizes_items = []

                    for size_item in sizes_items:
                        size_eur = size_item.get('name')


                        if category_name == '–î–µ–≤–æ—á–∫–∏' or category_name == '–ú–∞–ª—å—á–∏–∫–∏':
                            try:
                                size_rus = ''.join(i for i in size_eur.split()[-2] if i.isdigit())
                            except Exception:
                                size_rus = size_eur

                            if not size_rus:
                                size_rus = size_eur

                            if color_original is not None:
                                id_product_size = f"{reference}/{color_original.replace(' ', '-')}/{size_rus}"
                            else:
                                id_product_size = None

                        else:
                            if size_eur.isdigit():
                                size_rus = sizes_format(format='digit', gender=main_category, size_eur=size_eur)
                            elif not size_eur.isdigit():
                                size_rus = sizes_format(format='alpha', gender=main_category, size_eur=size_eur)
                            else:
                                size_rus = size_eur

                            if color_original is not None:
                                id_product_size = f"{id_product}/{color_original.replace(' ', '-')}/{size_eur}/{reference}"
                            else:
                                id_product_size = None

                        result_data.append(
                            {
                                '‚Ññ': None,
                                '–ê—Ä—Ç–∏–∫—É–ª': id_product_size,
                                '–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞': name_product,
                                '–¶–µ–Ω–∞, —Ä—É–±.*': price,
                                '–¶–µ–Ω–∞ –¥–æ —Å–∫–∏–¥–∫–∏, —Ä—É–±.': None,
                                '–ù–î–°, %*': None,
                                '–í–∫–ª—é—á–∏—Ç—å –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏–µ': None,
                                'Ozon ID': id_product_size,
                                '–®—Ç—Ä–∏—Ö–∫–æ–¥ (–°–µ—Ä–∏–π–Ω—ã–π –Ω–æ–º–µ—Ä / EAN)': None,
                                '–í–µ—Å –≤ —É–ø–∞–∫–æ–≤–∫–µ, –≥*': None,
                                '–®–∏—Ä–∏–Ω–∞ —É–ø–∞–∫–æ–≤–∫–∏, –º–º*': None,
                                '–í—ã—Å–æ—Ç–∞ —É–ø–∞–∫–æ–≤–∫–∏, –º–º*': None,
                                '–î–ª–∏–Ω–∞ —É–ø–∞–∫–æ–≤–∫–∏, –º–º*': None,
                                '–°—Å—ã–ª–∫–∞ –Ω–∞ –≥–ª–∞–≤–Ω–æ–µ —Ñ–æ—Ç–æ*': main_image,
                                '–°—Å—ã–ª–∫–∏ –Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–æ—Ç–æ': additional_images,
                                '–°—Å—ã–ª–∫–∏ –Ω–∞ —Ñ–æ—Ç–æ 360': None,
                                '–ê—Ä—Ç–∏–∫—É–ª —Ñ–æ—Ç–æ': None,
                                '–ë—Ä–µ–Ω–¥ –≤ –æ–¥–µ–∂–¥–µ –∏ –æ–±—É–≤–∏*': brand,
                                '–û–±—ä–µ–¥–∏–Ω–∏—Ç—å –Ω–∞ –æ–¥–Ω–æ–π –∫–∞—Ä—Ç–æ—á–∫–µ*': reference,
                                '–¶–≤–µ—Ç —Ç–æ–≤–∞—Ä–∞*': color_ru,
                                '–†–æ—Å—Å–∏–π—Å–∫–∏–π —Ä–∞–∑–º–µ—Ä*': size_rus,
                                '–†–∞–∑–º–µ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—è': size_eur,
                                '–°—Ç–∞—Ç—É—Å –Ω–∞–ª–∏—á–∏—è': status_size,
                                '–ù–∞–∑–≤–∞–Ω–∏–µ —Ü–≤–µ—Ç–∞': color_original,
                                '–¢–∏–ø*': type_product,
                                '–ü–æ–ª*': gender,
                                '–†–∞–∑–º–µ—Ä –ø–µ–ª–µ–Ω–∫–∏': None,
                                '–¢–ù –í–≠–î –∫–æ–¥—ã –ï–ê–≠–°': None,
                                '–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞': None,
                                '–°–µ–∑–æ–Ω': None,
                                '–†–æ—Å—Ç –º–æ–¥–µ–ª–∏ –Ω–∞ —Ñ–æ—Ç–æ': model_height,
                                '–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –Ω–∞ —Ñ–æ—Ç–æ': None,
                                '–†–∞–∑–º–µ—Ä —Ç–æ–≤–∞—Ä–∞ –Ω–∞ —Ñ–æ—Ç–æ': model_size,
                                '–ö–æ–ª–ª–µ–∫—Ü–∏—è': None,
                                '–°—Ç—Ä–∞–Ω–∞-–∏–∑–≥–æ—Ç–æ–≤–∏—Ç–µ–ª—å': None,
                                '–í–∏–¥ –ø—Ä–∏–Ω—Ç–∞': None,
                                '–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è': description,
                                '–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ —É—Ö–æ–¥—É': care,
                                '–°–µ—Ä–∏—è –≤ –æ–¥–µ–∂–¥–µ –∏ –æ–±—É–≤–∏': None,
                                '–ú–∞—Ç–µ—Ä–∏–∞–ª': material,
                                '–°–æ—Å—Ç–∞–≤ –º–∞—Ç–µ—Ä–∏–∞–ª–∞': composition_outer_shell,
                                '–ú–∞—Ç–µ—Ä–∏–∞–ª –ø–æ–¥–∫–ª–∞–¥–∞/–≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π –æ—Ç–¥–µ–ª–∫–∏': composition_lining,
                                '–ú–∞—Ç–µ—Ä–∏–∞–ª –Ω–∞–ø–æ–ª–Ω–∏—Ç–µ–ª—è': None,
                                '–£—Ç–µ–ø–ª–∏—Ç–µ–ª—å, –≥—Ä': None,
                                '–î–∏–∞–ø–∞–∑–æ–Ω —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä, ¬∞–°': None,
                                '–°—Ç–∏–ª—å': None,
                                '–í–∏–¥ —Å–ø–æ—Ä—Ç–∞': None,
                                '–í–∏–¥ –æ–¥–µ–∂–¥—ã': None,
                                '–¢–∏–ø –∑–∞—Å—Ç–µ–∂–∫–∏': None,
                                '–î–ª–∏–Ω–∞ —Ä—É–∫–∞–≤–∞': None,
                                '–¢–∞–ª–∏—è': None,
                                '–î–ª—è –±–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–ª–∏ –Ω–æ–≤–æ—Ä–æ–∂–¥–µ–Ω–Ω—ã—Ö': None,
                                '–¢–∏–ø —É–ø–∞–∫–æ–≤–∫–∏ –æ–¥–µ–∂–¥—ã': None,
                                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ —É–ø–∞–∫–æ–≤–∫–µ': None,
                                '–°–æ—Å—Ç–∞–≤ –∫–æ–º–ø–ª–µ–∫—Ç–∞': None,
                                '–†–æ—Å—Ç': None,
                                '–î–ª–∏–Ω–∞ –∏–∑–¥–µ–ª–∏—è, —Å–º': None,
                                '–î–ª–∏–Ω–∞ –ø–æ–¥–æ–ª–∞': None,
                                '–§–æ—Ä–º–∞ –≤–æ—Ä–æ—Ç–Ω–∏–∫–∞/–≥–æ—Ä–ª–æ–≤–∏–Ω—ã': None,
                                '–î–µ—Ç–∞–ª–∏': None,
                                '–¢–∞–±–ª–∏—Ü–∞ —Ä–∞–∑–º–µ—Ä–æ–≤ JSON': None,
                                'Rich-–∫–æ–Ω—Ç–µ–Ω—Ç JSON': None,
                                '–ü–ª–æ—Ç–Ω–æ—Å—Ç—å, DEN': None,
                                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä –≤ —É–ø–∞–∫–æ–≤–∫–µ': None,
                                '–ö–ª–∞—Å—Å –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏': None,
                                '–ü–µ—Ä—Å–æ–Ω–∞–∂': None,
                                '–ü—Ä–∞–∑–¥–Ω–∏–∫': None,
                                '–¢–µ–º–∞—Ç–∏–∫–∞ –∫–∞—Ä–Ω–∞–≤–∞–ª—å–Ω—ã—Ö –∫–æ—Å—Ç—é–º–æ–≤': None,
                                '–ü—Ä–∏–∑–Ω–∞–∫ 18+': None,
                                '–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ —Å–ø–µ—Ü–æ–¥–µ–∂–¥—ã': None,
                                'HS-–∫–æ–¥': None,
                                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≤–æ–¥—Å–∫–∏—Ö —É–ø–∞–∫–æ–≤–æ–∫': None,
                                '–û—à–∏–±–∫–∞': None,
                                '–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ': None,
                            }
                        )
                except Exception as ex:
                    print(f'sizes: {ex}')

            save_excel(data=result_data)


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø–∏—Å–∏ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º–∞—Ç xlsx
def save_excel(data: list) -> None:
    if not os.path.exists('results'):
        os.makedirs('results')

    if not os.path.exists('results/result_data.xlsx'):
        # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞–µ–º –µ–≥–æ —Å –ø—É—Å—Ç—ã–º DataFrame
        with ExcelWriter('results/result_data.xlsx', mode='w') as writer:
            DataFrame().to_excel(writer, sheet_name='–û–ó–û–ù', index=False)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞
    df = read_excel('results/result_data.xlsx', sheet_name='–û–ó–û–ù')

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —É–∂–µ –∑–∞–ø–∏—Å–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫
    num_existing_rows = len(df.index)

    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    dataframe = DataFrame(data)

    with ExcelWriter('results/result_data.xlsx', mode='a', if_sheet_exists='overlay') as writer:
        dataframe.to_excel(writer, startrow=num_existing_rows + 1, header=(num_existing_rows == 0), sheet_name='–û–ó–û–ù',
                           index=False)

    print(f'–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª "result_data.xlsx"')


def main():
    # get_category_urls(url=url, headers=headers)
    get_product_urls(category_data_list=category_data_list, headers=headers)
    # region = '–ì–µ—Ä–º–∞–Ω–∏—è'
    # id_region = id_region_dict.get(region)
    # if id_region is None:
    #     id_region = '24009400/20309422'
    # # id_categories_list = get_id_categories(headers=headers, params=params, id_region=id_region)
    # products_data_list = get_id_products(id_categories_list=id_category_list, headers=headers, params=params,
    #                                      id_region=id_region)
    # get_products_array(products_data_list=products_data_list, headers=headers, id_region=id_region)

    execution_time = datetime.now() - start_time
    print('–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω!')
    print(f'–í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã –ø—Ä–æ–≥—Ä–∞–º–º—ã: {execution_time}')


if __name__ == '__main__':
    main()
